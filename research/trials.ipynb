{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa43e1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00aeeb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\syedm\\\\Desktop\\\\Generative AI Medical Chat bot\\\\End-to-End-Medical-Chatbot-Hosted-on-Cloud-Platform-Vector-Base-\\\\research'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84e3e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  changing directory to main directory\n",
    "import os \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75ee7c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\syedm\\\\Desktop\\\\Generative AI Medical Chat bot\\\\End-to-End-Medical-Chatbot-Hosted-on-Cloud-Platform-Vector-Base-'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e7c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are document loaders in LangChain, used to import data into your chatbot from files like PDFs.\n",
    "\n",
    "# PyPDFLoader : Purpose: Loads content from a single PDF file.\n",
    "# DirectoryLoader Purpose: Loads multiple documents from a folder.\n",
    "from langchain.document_loaders import PyPDFLoader , DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# text splitter that breaks large documents into smaller chunks\n",
    "# RecursiveCharacterTextSplitter: Splits long text into manageable chunks (e.g., 500â€“1000 characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af484a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data From the PDF File\n",
    "def load_pdf_file(data):\n",
    "    loader= DirectoryLoader(data,  glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "    documents=loader.load()\n",
    "\n",
    "    return documents # it returns  the list of all extracted documents (text and metadata).\n",
    "\n",
    "\n",
    "# DirectoryLoader: Loads all .pdf files in the folder path data.\n",
    "# glob=\"*.pdf\": Filters only PDF files.\n",
    "# loader_cls=PyPDFLoader: Uses the PyPDFLoader to read each PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "007644af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calls the fucn and passes data path\n",
    "extarcted_data = load_pdf_file(data='Data/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15cbdfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMING CHUNKING OPERATIONS :\n",
    "def text_splitter(extarcted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 400 , chunk_overlap = 10)\n",
    "    text_chunks = text_splitter.split_documents(extarcted_data)\n",
    "    return  text_chunks\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32e85a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chunks 8681\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_splitter(extarcted_data)\n",
    "print('Length of Text Chunks', len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b5203de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDING MODEL FOR VECTOR EMBEDING FROM HUGGING FACE  and using all-MiniLM-L6-v2\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#This is a sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional \n",
    "# dense vector space and can be used for tasks like clustering or semantic search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7ed9d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Embeding model from Hugging face\n",
    "\n",
    "def download_hugging_face_embedings():\n",
    "    embedings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edf4bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syedm\\AppData\\Local\\Temp\\ipykernel_9128\\3695427722.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "embedings = download_hugging_face_embedings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c292ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "# checking whether our text is converting into vector embedings or not\n",
    "query_result = embedings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e1a7396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing environement so that can access pine cone api key \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35c13844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#  getting key fron env  variable and save it in a variale and call that in fucntion\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "OPEN_AI_API_KEY = os.environ.get('OPEN_AI_API_KEY')\n",
    "OPEN_AI_BASE_URL = os.environ.get('OPEN_AI_BASE_URL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fa534e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"medicalbot\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"medicalbot-oftdilp.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 384,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing these vectors inside pinecone , we ,manully create indexes in piencone on web and in python also ,  we prefer python\n",
    "\n",
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medicalbot\"\n",
    "\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384, \n",
    "    metric=\"cosine\", \n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\", \n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52224715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPEN_AI_API_KEY\"] = OPEN_AI_API_KEY\n",
    "os.environ[\"OPEN_AI_BASE_URL\"] = OPEN_AI_BASE_URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bb3266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now convert the chunks into vector embeding and store it in piencone database .\n",
    "# This creates a new Pinecone vector store and immediately:\n",
    "# Embeds your text chunks\n",
    "# Upserts (stores) them into the Pinecone index\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents= text_chunks,\n",
    "    index_name= index_name,\n",
    "    embedding= embedings, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aaa4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD EXISTING INDEX  (This loads a Pinecone index that already has vector embeddings stored inside it.) \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedings\n",
    ")\n",
    "\n",
    "# THIS IS DONE DUE TO :\n",
    "# Now you just want to query the index, not upload again\n",
    "# You want to perform a search (e.g., similarity search) on the existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "513fdbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8dd59802-3474-4a35-8c6f-4683e655120e', metadata={'author': '', 'creationdate': '2017-05-01T10:37:35-07:00', 'creator': '', 'keywords': '', 'moddate': '2017-05-01T10:37:35-07:00', 'page': 737.0, 'page_label': '738', 'producer': 'GPL Ghostscript 9.10', 'source': 'Data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'subject': '', 'title': '', 'total_pages': 759.0}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 21352\\nFood poisoning\\nAcne folliculitis. (Custom Medical Stock Photo. Reproduced by\\npermission.)'),\n",
       " Document(id='ff8b440f-1081-4d42-a67d-cf0678b5bebe', metadata={'author': '', 'creationdate': '2017-05-01T10:37:35-07:00', 'creator': '', 'keywords': '', 'moddate': '2017-05-01T10:37:35-07:00', 'page': 297.0, 'page_label': '298', 'producer': 'GPL Ghostscript 9.10', 'source': 'Data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'subject': '', 'title': '', 'total_pages': 759.0}, page_content='tion, can make the skin more susceptible to ICD.\\nAllergic contact dermatitis (ACD) results when\\nrepeated exposure to an allergen (an allergy-causing sub-\\nstance) triggers an immune response that inflames the\\nskin. Tens of thousands of drugs, pesticides, cosmetics,\\nfood additives, commercial chemicals, and other sub-\\nstances have been identified as potential allergens. Fewer'),\n",
       " Document(id='51599c0b-2a6c-4cc3-af31-1a0d92d57062', metadata={'author': '', 'creationdate': '2017-05-01T10:37:35-07:00', 'creator': '', 'keywords': '', 'moddate': '2017-05-01T10:37:35-07:00', 'page': 423.0, 'page_label': '424', 'producer': 'GPL Ghostscript 9.10', 'source': 'Data\\\\The_GALE_ENCYCLOPEDIA_of_MEDICINE_SECOND.pdf', 'subject': '', 'title': '', 'total_pages': 759.0}, page_content='thing that irritates the skin and is manifested by one or\\nmore lines of red, swollen, blistered skin that may itch or\\nGALE ENCYCLOPEDIA OF MEDICINE 21036\\nDermatitis')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING \n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "\n",
    "# INPUT \n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4cd74ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NOW WE WILL CONNECT THE LLM WITH THIS KNOWLEDGE BASE  , AND PEROFRM SEMANTIC SEARCHA NS ANSWER USER \n",
    "# QUERRY  \n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek/deepseek-r1:free\",\n",
    "    openai_api_base= OPEN_AI_BASE_URL,\n",
    "    openai_api_key= OPEN_AI_API_KEY ,\n",
    "    temperature=0.4,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89d83259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imran Khan, born on October 5, 1952, in Lahore, Pakistan, is a multifaceted figure known for his achievements in cricket, philanthropy, and politics. Here's an overview of his life and career:\n",
      "\n",
      "### **Early Life and Education**\n",
      "Imran Khan grew up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Imran Khan, born on October 5, 1952, in Lahore, Pakistan, is a multifaceted figure known for his achievements in cricket, philanthropy, and politics. Here's an overview of his life and career:\\n\\n### **Early Life and Education**\\nImran Khan grew up\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 13, 'total_tokens': 513, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek/deepseek-r1:free', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None}, id='run--9f3bd2b8-1ffa-40af-863b-4d06aa3f2d1e-0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it\n",
    "response = llm([HumanMessage(content=\"Tell me about imran khan\")])\n",
    "print(response.content)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "800200f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcdcbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7535502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly and gigantism are both caused by excessive growth hormone (GH) production, typically from a pituitary gland tumor. Gigantism occurs when excess GH arises in childhood before growth plate closure, leading to abnormal height. Acromegaly occurs in adulthood after growth plates close, causing enlarged bones and tissues, especially in hands, feet, and face.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is Acromegaly and gigantism both?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d163e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medical_chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
